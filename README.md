<div align="center">

# ğŸ”¬ NETAI â€” AI-Powered Kubernetes Chatbot for Network Diagnostics

**Google Summer of Code 2026 â€¢ National Research Platform (NRP)**

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)](https://fastapi.tiangolo.com)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Ready-326CE5.svg)](https://kubernetes.io)
[![License](https://img.shields.io/badge/License-Apache%202.0-red.svg)](LICENSE)

*An intelligent chatbot that integrates with NRP's managed LLM service to provide*
*natural language network diagnostics, anomaly explanation, and remediation strategies.*

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Quick Start](#-quick-start) â€¢ [API Reference](#-api-reference) â€¢ [Deployment](#-deployment) â€¢ [Testing](#-testing)

</div>

---

## ğŸ“‹ Overview

NETAI is a **Kubernetes-native chatbot** that leverages the National Research Platform's managed LLM service (supporting **Qwen3-VL**, **GLM-4.7**, and **GPT-OSS**) to help network operators:

- **Understand** complex network behaviors through natural language
- **Diagnose** anomalies with AI-powered root cause analysis
- **Remediate** issues with actionable, step-by-step strategies
- **Monitor** network health with context-aware telemetry integration

The chatbot integrates with **perfSONAR** measurement data and traceroute path analysis to provide real-time, data-driven network diagnostics assistance.

## âœ¨ Features

### ğŸ¤– LLM Integration
- **Multi-model support** â€” Qwen3-VL (reasoning), GLM-4.7 (fast), GPT-OSS (balanced)
- **OpenAI-compatible API** â€” Seamless integration with NRP's managed LLM endpoints
- **Streaming responses** â€” Real-time token-by-token streaming via Server-Sent Events
- **Context-aware** â€” Automatically injects network telemetry into LLM context

### ğŸ§  Prompt Engineering
- **Domain-specific system prompts** â€” Optimized for network diagnostics, anomaly explanation, and remediation
- **Query classification** â€” Automatically selects the best prompt strategy per query
- **Template engine** â€” Reusable, parameterized prompt templates
- **Context injection** â€” Real-time network telemetry injected into system prompts

### ğŸ“Š Network Diagnostics
- **perfSONAR integration** â€” Throughput, latency, packet loss, and jitter measurements
- **Traceroute analysis** â€” Hop-by-hop path analysis with problematic hop detection
- **Anomaly detection** â€” Threshold-based and statistical (z-score) anomaly detection
- **Health monitoring** â€” Real-time network path health classification

### ğŸŒ RESTful API
- **Chat endpoints** â€” Send messages, stream responses, manage conversations
- **Network endpoints** â€” Query network health, run diagnostics, execute traceroutes
- **Health probes** â€” Kubernetes-compatible liveness and readiness endpoints
- **OpenAPI docs** â€” Auto-generated Swagger UI at `/docs`

### â˜¸ï¸ Kubernetes Native
- **Helm chart** â€” One-command deployment with configurable values
- **GPU inference pods** â€” Ready for self-hosted LLM inference on NRP GPUs
- **Auto-scaling** â€” HPA based on CPU/memory utilization
- **Security** â€” Non-root containers, read-only filesystems, network policies

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Web UI (Chat Interface)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Application                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Chat API â”‚  â”‚ Network APIâ”‚  â”‚   Health Probes     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚              â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Context Manager                       â”‚  â”‚
â”‚  â”‚  â€¢ Conversation memory    â€¢ Query classification   â”‚  â”‚
â”‚  â”‚  â€¢ History windowing      â€¢ Telemetry injection    â”‚  â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜  â”‚
â”‚     â”‚                                              â”‚     â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”‚
â”‚  â”‚  LLM Client   â”‚           â”‚ Diagnostics Engine     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Qwen3-VL â”‚ â”‚           â”‚ â”‚perfSONARâ”‚ â”‚Tracer â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ GLM-4.7  â”‚ â”‚           â”‚ â”‚ Client  â”‚ â”‚ oute  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ GPT-OSS  â”‚ â”‚           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  Prompt Engineâ”‚           â”‚ â”‚ Anomaly Detector    â”‚â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚          â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  NRP LLM    â”‚                â”‚   perfSONAR     â”‚
    â”‚  Service    â”‚                â”‚   Measurement   â”‚
    â”‚  (Nautilus) â”‚                â”‚   Archive       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Git

### Local Development

```bash
# Clone the repository
git clone https://github.com/Mohammed-Anirudh/NETAI-LLM-Integration-Chatbot.git
cd NETAI-LLM-Integration-Chatbot

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -e ".[dev]"

# Copy environment config
cp .env.example .env

# Run the application (uses mock data by default)
make run
```

The chatbot will be available at **http://localhost:8000** with:
- ğŸ’¬ Chat UI at `/static/index.html`
- ğŸ“š API docs at `/docs`
- ğŸ“Š Network dashboard via API endpoints

### Docker

```bash
# Build and run with Docker Compose
docker compose up --build

# Or build manually
docker build -t netai-chatbot:latest .
docker run -p 8000:8000 netai-chatbot:latest
```

### With NRP LLM Service

To use real NRP LLM models, set your API key:

```bash
export LLM_API_KEY=your-nrp-api-key
export LLM_API_BASE_URL=https://llm.nrp-nautilus.io/v1
export ENABLE_MOCK_DATA=false
make run
```

## ğŸ“¡ API Reference

### Chat Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/chat/` | Send a message and get AI response |
| `POST` | `/api/v1/chat/stream` | Stream response via SSE |
| `GET` | `/api/v1/chat/conversations` | List active conversations |
| `GET` | `/api/v1/chat/conversations/{id}` | Get conversation history |
| `DELETE` | `/api/v1/chat/conversations/{id}` | Delete a conversation |

### Network Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/network/summary` | Network health overview |
| `POST` | `/api/v1/network/diagnostics` | Path-specific diagnostics |
| `POST` | `/api/v1/network/traceroute` | Run traceroute |
| `GET` | `/api/v1/network/nodes` | List NRP nodes |
| `GET` | `/api/v1/network/paths/{src}/{dst}` | Path health metrics |

### Example: Send a Chat Message

```bash
curl -X POST http://localhost:8000/api/v1/chat/ \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is the current throughput between San Diego and Chicago?",
    "model": "qwen3-vl",
    "source": "sdsc-prp.ucsd.edu",
    "destination": "nrp-chi.uchicago.edu"
  }'
```

### Example: Network Diagnostics

```bash
curl -X POST http://localhost:8000/api/v1/network/diagnostics \
  -H "Content-Type: application/json" \
  -d '{
    "source": "sdsc-prp.ucsd.edu",
    "destination": "nrp-chi.uchicago.edu"
  }'
```

## â˜¸ï¸ Deployment

### Kubernetes (Raw Manifests)

```bash
# Apply all manifests
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml
kubectl apply -f k8s/hpa.yaml

# Optional: GPU inference pod for self-hosted models
kubectl apply -f k8s/gpu-inference.yaml
```

### Helm Chart

```bash
# Install
helm install netai-chatbot helm/netai-chatbot/ \
  --namespace netai --create-namespace \
  --set secrets.llmApiKey=your-api-key

# Upgrade
helm upgrade netai-chatbot helm/netai-chatbot/ \
  --namespace netai \
  --set image.tag=v0.2.0

# Uninstall
helm uninstall netai-chatbot --namespace netai
```

### Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `LLM_API_BASE_URL` | `https://llm.nrp-nautilus.io/v1` | NRP LLM service endpoint |
| `LLM_API_KEY` | â€” | API key for NRP LLM service |
| `LLM_DEFAULT_MODEL` | `qwen3-vl` | Default model (qwen3-vl, glm-4.7, gpt-oss) |
| `ENABLE_MOCK_DATA` | `true` | Use simulated data for development |
| `PERFSONAR_URL` | â€” | perfSONAR measurement archive URL |
| `APP_PORT` | `8000` | Application port |
| `APP_LOG_LEVEL` | `info` | Log level |

## ğŸ§ª Testing

```bash
# Run full test suite with coverage
make test

# Quick tests without coverage
make test-quick

# Lint
make lint

# Format code
make format
```

### Test Coverage

The test suite covers:
- âœ… **API endpoints** â€” Chat, network telemetry, health checks
- âœ… **LLM client** â€” Mock responses, model selection, usage stats
- âœ… **Prompt engine** â€” Query classification, template rendering, context building
- âœ… **Diagnostics** â€” perfSONAR data, traceroute analysis, anomaly detection
- âœ… **Context manager** â€” Conversation lifecycle, history windowing, telemetry injection

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/netai_chatbot/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py               # Configuration (pydantic-settings)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py         # Chat endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py       # K8s health probes
â”‚   â”‚   â”‚   â””â”€â”€ telemetry.py    # Network telemetry endpoints
â”‚   â”‚   â”œâ”€â”€ models/             # Pydantic request/response models
â”‚   â”‚   â””â”€â”€ middleware.py       # CORS configuration
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ client.py           # LLM API client (OpenAI-compatible)
â”‚   â”‚   â”œâ”€â”€ providers.py        # NRP model configurations
â”‚   â”‚   â””â”€â”€ prompt_engine.py    # Prompt engineering strategies
â”‚   â”œâ”€â”€ diagnostics/
â”‚   â”‚   â”œâ”€â”€ perfsonar.py        # perfSONAR data integration
â”‚   â”‚   â”œâ”€â”€ traceroute.py       # Traceroute analysis
â”‚   â”‚   â”œâ”€â”€ anomaly.py          # Anomaly detection
â”‚   â”‚   â””â”€â”€ telemetry.py        # Telemetry processing
â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â””â”€â”€ manager.py          # Conversation context manager
â”‚   â””â”€â”€ utils/                  # Logging utilities
â”œâ”€â”€ static/                     # Web UI (HTML/CSS/JS)
â”œâ”€â”€ tests/                      # Comprehensive test suite
â”œâ”€â”€ k8s/                        # Kubernetes manifests
â”œâ”€â”€ helm/netai-chatbot/         # Helm chart
â”œâ”€â”€ Dockerfile                  # Multi-stage container build
â”œâ”€â”€ docker-compose.yml          # Local development setup
â””â”€â”€ docs/                       # Documentation
```

## ğŸ›  Technologies

| Category | Technologies |
|----------|-------------|
| **Backend** | Python 3.11+, FastAPI, Pydantic, uvicorn |
| **LLM** | OpenAI-compatible API, Qwen3-VL, GLM-4.7, GPT-OSS |
| **Diagnostics** | perfSONAR, traceroute analysis, statistical anomaly detection |
| **Infrastructure** | Kubernetes, Helm, Docker, GPU pods (NVIDIA) |
| **Testing** | pytest, pytest-asyncio, pytest-cov, httpx |
| **Quality** | ruff (lint/format), mypy (type checking), structlog |

## ğŸ¯ GSoC 2026 Proposal

This prototype demonstrates the core capabilities outlined in the **NETAI / LLM Integration & Kubernetes Chatbot** GSoC 2026 project:

- âœ… Kubernetes-native chatbot with REST API
- âœ… Integration with NRP's managed LLM service (OpenAI-compatible)
- âœ… Multi-model support (Qwen3-VL, GLM-4.7, GPT-OSS)
- âœ… Domain-specific prompt engineering for network diagnostics
- âœ… Context-aware responses with network telemetry injection
- âœ… perfSONAR measurement data integration
- âœ… Traceroute path analysis
- âœ… Anomaly detection and explanation
- âœ… Streaming responses (SSE)
- âœ… Conversation session management
- âœ… Kubernetes deployment manifests + Helm chart
- âœ… GPU inference pod configuration
- âœ… Docker containerization
- âœ… Comprehensive test suite
- âœ… Web-based chat interface

**Mentors:** Dmitry Mishin, Derek Weitzel

## ğŸ“„ License

Apache License 2.0 â€” See [LICENSE](LICENSE) for details.

---

<div align="center">
<strong>Built for GSoC 2026 â€¢ National Research Platform</strong>
</div>
